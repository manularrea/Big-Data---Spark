{"cells":[{"cell_type":"markdown","metadata":{"id":"4ovtxzqHG0ns"},"source":["# Shared variables"]},{"cell_type":"markdown","source":["## Setup Spark Environment"],"metadata":{"id":"i6tLh25gG7Ry"}},{"cell_type":"code","source":["from pathlib import Path\n","\n","installation_folder = Path(\"/content/spark-3.5.0-bin-hadoop3\")\n","\n","if not installation_folder.exists():\n","\n","  # Install Java locally\n","  !apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","\n","  # Download & decompress Spark\n","  !wget -q https://dlcdn.apache.org/spark/spark-3.5.0/spark-3.5.0-bin-hadoop3.tgz -O spark-3.5.0-bin-hadoop3.tgz\n","  !tar xf spark-3.5.0-bin-hadoop3.tgz\n","\n","  # Install finspark\n","  !pip install -q findspark\n","\n","  # Setup required environment variables\n","  import os\n","  os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","  os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.0-bin-hadoop3\"\n","\n","  print(\"Spark setup finished!\")\n","\n","else:\n","  print(\"Skipping Spark setup\")"],"metadata":{"id":"4PYP9_rGG7su","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702915159235,"user_tz":-60,"elapsed":35271,"user":{"displayName":"Miguel ﾃ］gel Corella","userId":"12810348842830866806"}},"outputId":"e72d14e0-4fa1-4984-808b-5a0e35035b33"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Spark setup finished!\n"]}]},{"cell_type":"markdown","metadata":{"id":"GeGpBGHlG0nt"},"source":["## Prepare the Spark context"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"B6LNCpgmG0nu","executionInfo":{"status":"ok","timestamp":1702915169249,"user_tz":-60,"elapsed":10032,"user":{"displayName":"Miguel ﾃ］gel Corella","userId":"12810348842830866806"}}},"outputs":[],"source":["# Import findpsark\n","import findspark\n","\n","# Configure the environment\n","findspark.init()\n","\n","# Import the Spark components required for the context creation\n","from pyspark import SparkConf, SparkContext\n","\n","# Configure and create the context\n","conf = SparkConf()\n","conf = conf.setAppName('mds-session')\n","conf = conf.setMaster('local[*]')\n","sc = SparkContext.getOrCreate(conf=conf)"]},{"cell_type":"markdown","metadata":{"id":"6n1ZSe70G0nv"},"source":["## Accumulators"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"xLNa4LOSG0nv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702915579357,"user_tz":-60,"elapsed":692,"user":{"displayName":"Miguel ﾃ］gel Corella","userId":"12810348842830866806"}},"outputId":"e9e51b1a-25a9-4adb-813f-3669fbbe138e"},"outputs":[{"output_type":"stream","name":"stdout","text":["2\n"]}],"source":["errors = sc.accumulator(0)\n","\n","def parseDate(date):\n","    try:\n","        year, month, day = date.split('-')\n","        return (year, month + '-' + day)\n","    except:\n","        errors.add(1)\n","\n","rdd1 = sc.parallelize(['2014-12-31', '2015-01-25', '2016-05-17', '2016-', '2017-01-05', '2014-06'])\n","rdd2 = rdd1.map(parseDate)\n","results = rdd2.collect()\n","\n","print(errors.value)"]},{"cell_type":"markdown","metadata":{"id":"hDU7TbsLG0nv"},"source":["## Broadcast variables"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"KWacbJpDG0nv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702915175248,"user_tz":-60,"elapsed":772,"user":{"displayName":"Miguel ﾃ］gel Corella","userId":"12810348842830866806"}},"outputId":"84de0d33-8959-4939-e1b9-9f181c1cb247"},"outputs":[{"output_type":"stream","name":"stdout","text":["[('Cristina', 'Lengua', 10), ('Cristina', 'Matematicas', 8), ('Lucia', 'Lengua', 7), ('Lucia', 'Matematicas', 9)]\n"]}],"source":["students = dict()\n","students['25'] = 'Cristina'\n","students['12'] = 'Lucia'\n","studentsBC = sc.broadcast(students)\n","\n","subjects = dict()\n","subjects['0'] = 'Lengua'\n","subjects['1'] = 'Matematicas'\n","subjectsBC = sc.broadcast(subjects)\n","\n","rdd1 = sc.parallelize([(25, 0, 10), (25, 1, 8), (12, 0, 7), (12, 1, 9)])\n","\n","def translate(element):\n","    return (studentsBC.value[str(element[0])], subjectsBC.value[str(element[1])], element[2])\n","\n","rdd2 = rdd1.map(translate)\n","print(rdd2.collect())"]},{"cell_type":"markdown","metadata":{"id":"lMrMOrxAG0nw"},"source":["## Close the Spark context"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bKzStp8pG0nw"},"outputs":[],"source":["sc.stop()"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.0"},"colab":{"provenance":[{"file_id":"1Zldce11Zae1sLbt4lurrgeDPfpTsGV2b","timestamp":1702201350958}]}},"nbformat":4,"nbformat_minor":0}